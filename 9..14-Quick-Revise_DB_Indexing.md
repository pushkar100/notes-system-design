# Quick Revision: DB Indexing

Indexing is the **"Speed Layer"** of your database. Without indexes, a database is just a messy pile of files that you have to read from start to finish to find anything

## Table of Contents

- [Quick Revision: DB Indexing](#quick-revision-db-indexing)
  - [The Core Concept using a Book Analogy](#the-core-concept-using-a-book-analogy)
  - [The Default Choice of B-Tree Indexes](#the-default-choice-of-b-tree-indexes)
  - [The Write-Heavy Choice of LSM-Trees](#the-write-heavy-choice-of-lsm-trees)
  - [Hash indexes](#hash-indexes)
  - [Deep Dive on Geospatial Indexes](#deep-dive-on-geospatial-indexes)
  - [Deep Dive on Inverted Indexes](#deep-dive-on-inverted-indexes)
  - [Index optimization patterns](#index-optimization-patterns)
  - [Tying it to CAP Theorem](#tying-it-to-cap-theorem)
  - [Summary of which indexing to choose](#summary-of-which-indexing-to-choose)

## The Core Concept using a Book Analogy

Imagine a textbook with 1,000 pages
- Without an Index: To find the word "mitochondria", you must read every single page from 1 to 1,000 (This is a *Full Table Scan* - `O(N)`)
- With an Index: You go to the back of the book, look up "M", find "mitochondria: Page 42", and jump straight there. (This is an *Index Seek* - `O(log N)`)
- Physical Storage: ***Data on disk is slow to find***. ***Indexes create a separate, smaller data structure (usually in RAM or optimized on disk) that points to the exact physical location of the row***
- The Cost (The Trade-off): 
	- **Reads become Fast**: You skip 99% of the data.
	- **Writes become Slow**: Every time you `INSERT` or `UPDATE` a row, you must also update the Index. You do *double* the work!

## The Default Choice of B-Tree Indexes

Used by: **PostgreSQL, MySQL, Oracle**

Why is it the default? 
- Disks hate "jumping around" (Random I/O). ***Disks love reading continuously***
- A **B-Tree is designed to be "short and fat,"** *minimizing* the number of disk jumps needed to find data

The Structure: 
- A B-Tree ***keeps data Sorted***. It *balances itself* so that *all leaf nodes are at the same depth* (**`O(N)` read**)
- Example Root Node: "Values 0-50 go Left, 51-100 go Right"
- Example Leaf Node: *Contains the **actual pointer** to the data row on the disk*

```
           [ 50 ]
          /      \
      [ 25 ]      [ 75 ]
     /    \       /    \
 [1..24] [26..49] [51..74] [76..100] <-- Leaf Nodes (Sorted)
```
- Pros: **Great for Range Queries** (`WHERE age > 25`) *because the data is **sorted***
- Cons: **Writing is expensive because the tree constantly re-balances itself**

Anatomy of a single node:
```
Every node contains Keys (sorted data) and Pointers (references to child nodes).

Keys (10, 20, 30): Act as "Signposts" or separators

Pointers: Direct traffic. The left pointer leads to numbers smaller than 10. 
The right pointer leads to numbers larger than 30

       +---------------------------------------------+
       |  ptr   Key1   ptr   Key2   ptr   Key3   ptr |
       +---|-----|------|-----|------|-----|------|--+
           |     |      |     |      |     |      |
    Values < 10  |  10 < x < 20      |  20 < x < 30
                10                  20           30
```

Full tree anatomy:
```
Notice how the tree is "Short and Wide (High Fan-out)"
This is why it is fast; you make very few "hops" (disk reads) to find data

Scenario: We are searching for value 45

LEVEL 0           [      30      |      60      ]   <-- Root Node
(Root)           /               |               \
                /                |                \
               v                 v                 v
            ( < 30 )        ( 30 < x < 60 )     ( > 60 )
            /                    |                    \
LEVEL 1    /                     |                     \
(Internal)[ 10 | 20 ]       [ 40 | 50 ]            [ 70 | 80 | 90 ]
          /    |    \       /    |    \            /    |    |    \
         /     |     \     /     |     \          /     |    |     \
LEVEL 2 v      v      v   v      v      v        v      v    v      v
(Leaves)[5]  [15]   [25] [35]  [45]   [55]     [65]   [75] [85]   [95]
                                 ^
                                 |
                          FOUND IT! (Matches 45)
```

**B+ Trees**

A *variation* of B-Trees. It is ***optimized for Range Scans*** (e.g., 	SELECT * FROM users WHERE id > 100`)

***The critical difference***: 
- Internal Nodes are "Routers" only. They do not store data
- All real data lives at the bottom on Leaf Nodes

```
Scenario: We want to find Value 55 and then scan everything after it

LEVEL 0               [      50       ]     <-- Router (Key Only)
(Internal)           /                 \        No Data here!
                    /                   \
                   v                     v
LEVEL 1      [ 20 | 30 ]             [ 60 | 80 ]   <-- Router
(Internal)   /    |    \             /    |    \
            /     |     \           /     |     \
           v      v      v         v      v      v
LEVEL 2  [10]--[20|25]--[30|40]--[50|55]--[60|70]--[80|90]  <-- LEAVES
(Data)    ^                       ^  ^
          |                       |  |
      Data is                  Target Found!
      Here (Record 10)         (Record 55)
```

## The Write-Heavy Choice of LSM-Trees

Used by: **Cassandra, RocksDB, Kafka**

The Concept: *B-Trees are too slow for massive write loads* (like IoT sensors). 
- ***Log-Structured Merge (LSM) Trees optimize for writing***

How it works:
- **MemTable (RAM)**: Writes land here first (`In-Memory`). **Fast** because no disk I/O
- **SSTable (Disk)**: When RAM fills up, the data is flushed to disk as an immutable (unchangeable) file
- **Compaction**: Background processes merge these files to clean up duplicates

```
[ Write Request ]
           |
           v
    +-------------+       (Flushed when full)
    |  MemTable   | -------------------------> [ SSTable File 1 ]
    | (In RAM)    |                            [ SSTable File 2 ]
    +-------------+                            [ SSTable File 3 ]
```
- **Pros**: ***Insanely fast writes*** (just appending to a file)
- **Cons**: ***Slower reads*** (you might have to **check MemTable AND multiple SSTables** to find the latest value)

## Hash indexes

Used by: **Redis, Programming Language Maps**

The Concept:Use a ***hash function to map a key directly to a memory address***

Time Complexity: **`O(1)` (Instant)**

The Fatal Flaw: **You cannot do Range Queries**
- If you hash `"Age: 25"`, you cannot ask `"Give me all ages > 25"`. The hash of 26 looks nothing like the hash of 25!

Use Case: **Exact lookups only** (`WHERE id = 123`)

## Deep Dive on Geospatial Indexes

Used by: **Uber, Yelp, Google Maps**

Problem: How do you find "Coffee shops near me"? 
- Standard B-Trees fail here because ***latitude and longitude are two dimensions***, but ***B-Trees sort in one dimension***

**Approach A: QuadTrees**
- We recursively divide the world into 4 squares (quadrants)
- If a square has too many points, split it into 4 smaller squares
- Search: "Which square am I in? Who else is in this square?"

```
     Step 1: World       Step 2: Split NE      Step 3: Split again
    +-------+-------+   +-------+---+---+
    |       |       |   |       | C | D |
    |   NW  |   NE  |   |   NW  +---+---+
    |       |       |   |       | A | B | <--- User is here
    +-------+-------+   +-------+---+---+
    |       |       |   |       |       |
    |   SW  |   SE  |   |   SW  |   SE  |
    |       |       |   |       |       |
    +-------+-------+   +-------+-------+
```

**Approach B: Geohash (String Encoding)**
- We ***convert 2D coordinates into a 1D string/number by interleaving bits***
- Concept: The *longer the shared prefix, the closer the points are*
	- `dr5r` is a city
	- `dr5ru` is a neighborhood in that city
	- `dr5ru7` is a street in that neighborhood
- Search: `WHERE hash LIKE 'dr5ru%'` (This is a standard B-Tree range query!)

**Pros/Cons:**
- **Geohash**: 
	- **Easy to implement in standard DBs** (it's just a *string*)
	- **Edge cases exist** (two close points might have totally different hashes at the border).
- **Quadtree**: 
	- **Conceptually cleaner for "K-Nearest Neighbors"** but **harder to implement on disk**

## Deep Dive on Inverted Indexes

Used by: **Elasticsearch, Google Search**

Problem: How do you search for "Apple" in 1 billion tweets? `LIKE '%Apple%'` is too slow (Full Scan).

The Concept: 
- Flip the data inside out. Instead of `Document -> Words`, **store `Word -> List `of Documents**

|Token (Word)|Posting List (Document IDs)|
|------------|---------------------------|
|"Apple"     |[ Doc_1, Doc_5, Doc_99 ]   |
|"Banana"    |[ Doc_2, Doc_5 ]           |
|"Code"      |[ Doc_1 ]                  |

The Query: "Find documents with Apple AND Banana".
1. Look up `"Apple": [1, 5, 99]`
2. Look up `"Banana": [2, 5]`
3. Intersect: `[5] -> Document 5` is the match

## Index optimization patterns

**A. Composite Indexes (The "Leftmost Prefix" Rule)**

If you often query by `WHERE First_Name = 'A' AND Last_Name = 'B'`, **create one index on `(First_Name, Last_Name)`**

- Rule: The index works like a phonebook sorted by Last Name, then First Name
- Trap: If you have index (A, B), *you cannot use it to search just for B*. You *must start from the left* (A)

**B. Covering Indexes (The "Free Lunch")**

Usually, the DB checks the index to find the ID, then goes to the main table to fetch the rest of the data
- *Optimization*: If your *index contains all the columns you asked for*, the DB never touches the main table. It *answers directly from the index*
- Query: `SELECT Name FROM Users WHERE Age = 25`
- Index: `(Age, Name)`
- Result: Zero disk lookups to the main table. ***Extremely fast!***

## Tying it to CAP Theorem

Indexing affects your system's position in the CAP triangle.

Read Availability (AP):
- ***Adding more indexes makes reads faster and more reliable (Higher Availability)***
- Replicating indexes (e.g., in Elasticsearch) allows searching even if primary nodes fail

Write Consistency (CP):
- ***Indexes hurt write availability***
- If you require Strong Consistency, every write must update all indexes before returning success
- If you have 10 complex indexes (Geo, Text, B-Tree), a single write might fail or time out because it's waiting for indexes to update

|Index Type|Structure       |Best For                      |Complexity   |Example DB      |
|----------|----------------|------------------------------|-------------|----------------|
|B-Tree    |Sorted Tree     |General Purpose, Range Queries|`O(logN)`      |MySQL, Postgres |
|LSM-Tree  |Log Files       |High Write Throughput         |Write: `O(1)`  |Cassandra       |
|Hash      |Hash Map        |Exact Match Only              |`O(1)`         |Redis           |
|Geospatial|QuadTree/Geohash|"Near Me" Queries             |`O(logN)`      |PostGIS, Uber H3|
|Inverted  |Token Map       |Full Text Search              |`O(1)` per term|Elasticsearch   |

## Summary of which indexing to choose

**Index Optimization Cheatsheet**
1. **Composite Indexes (The "Filter" Optimization)**
	- Trigger: Query ***filters*** by ***multiple columns*** (e.g., `WHERE A=1 AND B=2`)
	- Benefit: Filters data using all criteria instantly; avoids scanning results twice
	- Rule: Leftmost Prefix. `Index (A, B)` works for `A` and `A+B`, ***but NOT just the `B` column***
2. **Covering Indexes (The "Fetch" Optimization)**
	- Trigger: Query `SELECT`s ***only a few columns*** found in the index
	- Benefit: Answers query 100% from RAM (Index Only Scan)
	- Result: Zero disk lookups; extremely fast..

|Optimization|Target Clause   |Goal                          |
|------------|----------------|------------------------------|
|Composite Index|WHERE           |Faster Searching. Filter by multiple criteria.|
|Covering Index|SELECT          |Faster Retrieval. Avoid touching the hard disk.|
