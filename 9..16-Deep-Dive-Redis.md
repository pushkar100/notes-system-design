# Redis Deep Dive

## Table of Contents

- [Redis Deep Dive](#redis-deep-dive)
  - [What is Redis?](#what-is-redis)
  - [Single-Threaded nature](#single-threaded-nature)
  - [Persistence or The Safety Net](#persistence-or-the-safety-net)
  - [Redis Infrastructure and Scaling](#redis-infrastructure-and-scaling)
    - [Replication for High Availability](#replication-for-high-availability)
    - [Clustering or Sharding](#clustering-or-sharding)
    - [How does the phone book work for cluster slots?](#how-does-the-phone-book-work-for-cluster-slots)
    - [Which scaling mechanism to select?](#which-scaling-mechanism-to-select)
  - [Data structures Redis supports](#data-structures-redis-supports)
  - [Using Redis in the real world or Applications of Redis](#using-redis-in-the-real-world-or-applications-of-redis)
    - [Use Redis for Caching](#use-redis-for-caching)
    - [Distributed Locking with Redis](#distributed-locking-with-redis)
    - [Implementing Leaderboards in Redis](#implementing-leaderboards-in-redis)
    - [Implementing Streams or PubSub](#implementing-streams-or-pubsub)
      - [Why would you not just use Kafka over Redis?](#why-would-you-not-just-use-kafka-over-redis)
    - [Rate limiting using Redis](#rate-limiting-using-redis)
    - [Geospatial or Proximity use case](#geospatial-or-proximity-use-case)
  - [List of common Redis commands](#list-of-common-redis-commands)

## What is Redis?

Redis is an **in-memory, single-threaded** data structure store written in **C**

1. **"In-Memory"**: Data lives in RAM, making it *incredibly fast (sub-millisecond latency)*
2. **"Data Structure Store"**: Unlike a simple Key-Value store (which just holds strings), Redis *understands complex data types* like Lists, Sets, and Hashes
3. **"Single-Threaded"**: It processes commands one at a time
	- Why? It *eliminates the need for complex locking and race condition handling within the engine itself*. Because RAM is so fast, the CPU is rarely the bottleneck—network I/O is
	- Trade-off: Because it is in-memory, *you **sacrifice Durability** for Speed*. If the server loses power, you lose RAM data
	- Mitigation: Redis supports **AOF (Append Only File)** and **Snapshots (RDB)** to save data to disk, but it is *not as strictly durable as a relational DB* (e.g., PostgreSQL)

## Single-Threaded nature

The Single-Threaded Event Loop
- Redis uses a single thread to handle all read/write commands
- How it works: All requests from thousands of clients enter a ***single queue***. The CPU processes them one by one, *sequentially*
- Why? It *removes the need for complex "locks" (mutexes) that slow down multi-threaded databases*. Because it's in RAM, the *bottleneck is usually the Network, not the CPU*

```
[ Client 1 ] -- "SET A 1" --\
[ Client 2 ] -- "GET B" ----> [ COMMAND QUEUE ] --> [ CPU (The Worker) ]
[ Client 3 ] -- "INCR A" ---/     (Ordered)         ( fast! fast! fast! )
                                      |
                                      v
                                 [ Memory ]
```

## Persistence or The Safety Net

Since Redis is in-memory, a power outage wipes it!

Two mechanisms save data to disk:
1. **RDB (Snapshot)**: Takes a photo of the database every `N` minutes
2. **AOF (Append Only File)**: *Logs every single write command* (`SET, INCR`) *to a file*. ***Slower but safer***

```
MEMORY (RAM)                  DISK (Storage)
+------------------------+      +-----------------------+
| Key: "User:1" Value: X |      | [ RDB Snapshot ]      |
| Key: "User:2" Value: Y |  --> | (Copy of RAM at 5pm)  |
+------------------------+      +-----------------------+
           |
           | (Every Write Command)
           v
      +-----------------------+
      | [ AOF Log ]           |
      | 1. SET User:1 X       |
      | 2. SET User:2 Y       |
      +-----------------------+
```

## Redis Infrastructure and Scaling

How does Redis grow *beyond* a single server?

Two approaches:

### Replication for High Availability

- You run a ***Primary node*** and ***one or more Replicas***
- Writes: ***Only goes to the Primary***
- Reads: Can be ***distributed across Replicas to handle heavy traffic***
- If Primary dies, a *Replica is promoted* to keep the system alive

```
                               +-------------+
                               | Application |
                               +-------------+
                                 |         |
                  (1) WRITE      |         | (2) READ
                  (SET key val)  |         | (GET key)
                                 v         v
                       +-------------+   +-------------+
                       |             |   |             |
            +--------->|   PRIMARY   |   |  REPLICA 1  |
            |          |  (Master)   |   | (Read-Only) |
            |          +-------------+   +-------------+
            |                 |
            |                 | (3) Async Replication
            |                 | (Stream of commands)
            |                 v
            |          +-------------+
            |          |             |
            +----------|  REPLICA 2  |
      (Failover Path)  | (Read-Only) |
                       +-------------+
```

### Clustering or Sharding

- Redis uses **Hash Slots** to split data across multiple nodes **(PRECONFIGURED SLOTS. Why? Easy to move data across partitions)**
- Total Slots: `16,384`
- Every key is hashed to a slot: `CRC16(key) % 16384`
- **Client Intelligence**: Clients (like your Java/Python app) keep a "phone book" mapping slots to nodes. They connect directly to the correct node.
- **Gossip Protocol**: Nodes talk to each other. If a client hits the wrong node, the node says "MOVED" (This is a redirection, similar to an `HTTP 301`) and points to the right one

> CRC16 in Redis is a **checksum algorithm** used to decide which hash slot a key belongs to in Redis Cluster

```
           Key: "User:123"
                  |
        Hash Algorithm (CRC16)
                  |
                  v
             Result: 5000
                  |
    +-------------+-------------+
    | Does Node A own Slot 5000?|
    +-------------+-------------+
    |             |             |
   YES            NO            NO
    |             |             |
[ Node A ]    [ Node B ]    [ Node C ]
(0-5500)     (5501-11000)  (11001-16384)
    ^
    |
  Data stored here!
```
```
                  Total Slots: 16,384
      [0 ........................................ 16383]
                   |              |              |
        +----------v---+   +------v-------+   +--v-----------+
        |    NODE A    |   |    NODE B    |   |    NODE C    |
        |  (Slots:     |   |  (Slots:     |   |  (Slots:     |
        |   0 - 5500)  |   |  5501-11000) |   |  11001-16383)|
        +--------------+   +--------------+   +--------------+
               ^                  ^                  ^
               |                  |                  |
               +--------< GOSSIP PROTOCOL >----------+
               (Nodes exchange state: "I am alive",
                "I hold these slots")
```

**The "MOVED" Redirection Flow**

What happens when a "Dumb Client" (one that doesn't cache the map) or a client with an outdated map hits the wrong node?

```
   User wants key: "user:100"
   Math: CRC16("user:100") % 16384 = Slot 7000

       +--------+
       | CLIENT |
       +--------+
           |
           | 1. GET "user:100" (Hits Node A by mistake)
           v
    +--------------+
    |    NODE A    |  <--- Checks Slot Map: "Slot 7000 is not mine!"
    | (Slots 0-5k) |       "It belongs to Node B at 192.168.0.2"
    +--------------+
           |
           | 2. Error: MOVED 7000 192.168.0.2:6379
           v
       +--------+
       | CLIENT | <--- Updates internal "Phone Book" (Slot Map)
       +--------+
           |
           | 3. GET "user:100" (Retries correctly)
           v
    +--------------+
    |    NODE B    |
    | (Slots 5k+)  | <--- "Slot 7000 is mine. Here is the data."
    +--------------+
```

### How does the phone book work for cluster slots?

Steps:
1. The Ask: On startup, the client connects to any Redis node and runs `CLUSTER SLOTS`. The node replies with the full map (the "phone book")
2. The Save: The client saves this map in its own local memory (RAM).
3. The Use: When you request a key, the client checks its saved map and connects directly to the right node
4. The Update: If a node replies with `MOVED` (meaning the map changed), the client updates its saved map instantly!

### Which scaling mechanism to select?

**Do you have more data than a single machine's RAM can hold?**
- **YES**: You must use ***Clustering***. Logic: A single server physically cannot store your data. You have to split (shard) it across multiple servers
- **NO**: You should use ***Replication***. Logic: It is simpler to manage. One primary node can handle the writes, and you add Replicas if you need to handle more read traffic or need backup if the primary fails

## Data structures Redis supports

Modern Redis is ***more than just Key-Value strings***

Data Structures:
1. Strings (The Basic Block): Used for caching HTML, JSON blobs, or simple counters (`O(1)`)
2. Hash or Object: Perfect for storing objects like a user profile. You can modify a single field (like age) *without* reading the whole object
3. ***Sorted Sets*** (The Leaderboard): The *most unique* Redis structure. Every item has a Score. Redis keeps them sorted by score automatically 
	- Structure: Uses something known as **Skip List** internally for speed (`O(log N)` which is much faster than `ORDER BY`)
	- Use Case: ***Leaderboards, Priority Queues***

```
Key: "page:home"
+--------------------------------------------------+
| "<html><body>Welcome to My Site...</body></html>"|
+--------------------------------------------------+
```
```
Key: "user:100"
+-----------+-------------+
| Field     | Value       |
+-----------+-------------+
| name      | "Alice"     |
| role      | "Admin"     |
| logins    | "42"        |
+-----------+-------------+
```
```
Key: "game_leaderboard"
(Ordered by Score Low -> High)

   [Score: 10]  -->  "Player_C"
       ^
       |
   [Score: 50]  -->  "Player_A"
       ^
       |
   [Score: 99]  -->  "Player_B" (Top Rank)
```

## Using Redis in the real world or Applications of Redis

Use cases:
1. Distributed caching
2. Distributed locking
3. Streams and Pub/Sub
4. Rate limiting
5. Geospatial or Proximity questions (Ex: Uber)

### Use Redis for Caching

The default use case. Store expensive database results in Redis! 

Take care of expiry and eviction though:
- **TTL** (Time To Live): Always set an expiration (`EXPIRE`) so memory doesn't fill up
- **Eviction Policy**: When full, Redis deletes keys. Standard is LRU (Least Recently Used).

**Caching & The "Hot Key" Problem**

*Problem*: If a celebrity tweets, millions of people request the same key (`tweet:123`)
- This traffic all hits one specific shard, overloading it
- *Solution*: Store copies of the key with random suffixes (`tweet:123_1`, `tweet:123_2`) to spread the load (**Jitter/Randomization**)

```
 TRAFFIC SPIKE (1M req/s)
       |
       |  (Without Fix: CRASH)
       v
  [ Node A ] (Holds "tweet:123")
  [ Node B ] (Idle)
  [ Node C ] (Idle)

       vs

  (With Fix: Replica Keys)
       |
    /--+--\
   v   v   v
[Node A] [Node B] [Node C]
(copy_1) (copy_2) (copy_3)
```

### Distributed Locking with Redis

For this case, it is ***good that Redis is Single Threaded***! 
- *Why*? Because the requests are stored in queue and picked up at Redis' own pace. No complex locking mechanisms nor race-conditions!

```
[ Client 1 ] -- "SET A 1" --\
[ Client 2 ] -- "GET B" ----> [ COMMAND QUEUE ] --> [ CPU (The Worker) ]
[ Client 3 ] -- "INCR A" ---/     (Ordered)         ( fast! fast! fast! )
                                      |
                                      v
                                 [ Memory ]
```

**Scenario**: Ensure only one service processes a refund at a time
- Mechanism: `SETNX (Set if Not Exists)` + `TTL (Expiration)`

**Critical Safety**: ***Always set a TTL on the lock***! If the worker crashes before releasing the lock, the TTL ensures it auto-releases eventually

```
     [ Process A ]             [ Process B ]
          |                         |
          | (1) Try SETNX           | (2) Try SETNX
          v                         v
    +-------------------------------------+
    |      REDIS LOCK: "refund_123"       |
    |      Value: "Locked"                |
    |      TTL: 10 seconds                |
    +-------------------------------------+
          ^
          |
     (Process A wins!)
     (Process B receives "0" -> Fail/Wait)
```

### Implementing Leaderboards in Redis

- Scenario: Top 10 "Liked" posts on Twitter
- Structure: Sorted Set (`ZSET`)
- How it works:
	- Key: `posts:likes`
	- Value: `PostID`
	- Score: `LikeCount`
	- Operations:
		- `ZADD posts:likes 500 "post_A"` (Set Post A to 500 likes)
		- `ZINCRBY posts:likes 1 "post_A"` (Increment likes)
		- `ZREVRANGE posts:likes 0 9` (Get top 10)
		- Performance: Uses a ***Skip List*** internally. `O(log N)` for updates and reads. Much faster than SQL `ORDER BY`

### Implementing Streams or PubSub

**Pub/Sub (The "Live Radio" Model)**
- This is Fire-and-Forget
- Publishers send messages to a channel, and Subscribers listen
- Why use it: It is ***incredibly fast and simple for real-time data***
- The Catch: ***If a subscriber is offline, they miss the message forever***. ***No history is saved***
- Example: A live sports scoreboard. If you tune in late, you just see the current score; you don't need to replay every goal that happened 2 hours ago.

**Redis Streams (The "WhatsApp Group" Model)**
- This was added (`v5.0`) to fix the "missing data" problem. ***It acts like a log file***
- Why use it: It *saves messages* so consumers can read them later or catch up if they crash. *It supports "Consumer Groups" (sharing the work)*
- Example: An order processing system. If the "Payment Service" is down, the order message stays in the Stream until the service comes back online to process it

```
(A) PUB/SUB: "Fire and Forget"
   +-----------+                  +-------------+
   | Publisher | --(msg: Goal!)-->|  CHANNEL    | --(msg: Goal!)--> [Subscriber A] (Online)
   +-----------+                  | "sports"    |
                                  |             | --(msg: Goal!)--> [Subscriber B] (OFFLINE!)
                                  +-------------+                         ^
                                                                          |
                                                                   (Message Lost!)

(B) STREAMS: "Log & Replay"
   +-----------+                  +-------------+
   | Publisher | --(msg: Order)-->|   STREAM    | <--(read last)---- [Consumer A] (Online)
   +-----------+                  | "orders"    |
                                  | [ID1: Order]|
                                  | [ID2: Order]| <--(read catchup)-- [Consumer B] (Was Offline)
                                  +-------------+
```

#### Why would you not just use Kafka over Redis?

You usually choose Redis for queues ***when you already have Redis in your stack and don't want the headache of managing a separate, complex system***

* Use **Kafka** if you need to *store terabytes of history, replay events from a year ago, or handle millions of events per second (**massive scale**)*. ***Kafka is a heavy beast to manage***

Summary Case: If you are building a simple background job system (like sending emails) or a real-time chat for a startup, Redis is perfect. Bringing in Kafka for that would be overkill—like renting a freight train to deliver a pizza

### Rate limiting using Redis

Scenario: "Allow max 10 requests per minute."

***Fixed Window (Simple):***
- Key: `userIP:minute_timestamp`
- Value: `Counter`
- Logic: `INCR`. If `> 10`, Reject. Set `EXPIRE` to 60s

```
Request 1 -> INCR "user:123" -> (Val: 1) -> OK
Request 2 -> INCR "user:123" -> (Val: 2) -> OK
...
Request 6 -> INCR "user:123" -> (Val: 6) -> REJECT!

[ Timer ] --> (At 60s) --> DELETE "user:123" (Reset)
```

***Sliding Window (Advanced):***
- Use a Sorted Set
- Score = Timestamp of request
- Logic: When a request comes in, remove all items older than 1 minute (`ZREMRANGEBYSCORE`). Count remaining. If `Count < 10`, Add new request

### Geospatial or Proximity use case

Scenario: Uber/Yelp

Commands:
- `GEOADD map_key -73.9 40.7 "Driver_A"` (Stores driver)
- `GEOSEARCH map_key ... BYRADIUS 5 km` (Finds drivers).

Under the hood:
- It uses **Geohashing**: It converts 2D Lat/Lon into a 1D number (score) and stores it in a Sorted Set
- This means `GEOSEARCH` is just a *range query on a Sorted Set!*

## List of common Redis commands

|#     |Command         |What it does                  |Example             |
|------|----------------|------------------------------|--------------------|
|1     |SET             |Saves a key-value pair.       |SET user:1 "John"   |
|2     |GET             |retrieves a value.            |GET user:1          |
|3     |DEL             |Deletes a key instantly.      |DEL user:1          |
|4     |EXPIRE          |Sets a self-destruct timer (in seconds).|EXPIRE sess:123 30  |
|5     |TTL             |Checks how many seconds are left before deletion.|TTL sess:123        |
|6     |INCR            |Adds 1 to a number (great for counters).|INCR page_views     |
|7     |EXISTS          |Checks if a key is already there (True/False).|EXISTS user:1       |
|8     |HGETALL         |Gets all fields/values of a Hash (like a JSON object).|HGETALL user:profile|
|9     |LPUSH           |Adds an item to a List (Queue).|LPUSH jobs "email_1"|
|10    |SADD            |Adds a unique item to a Set (no duplicates).|SADD tags "urgent"  |
